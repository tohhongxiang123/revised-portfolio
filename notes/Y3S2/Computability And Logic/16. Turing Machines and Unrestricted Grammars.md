# Turing Machines and Unrestricted Grammars

# Countable/Uncountable Sets

- The cardinality of a set is the number of elements in the set

Finite sets $A$ and $B$ have the same size if they have the same number of elements in each of them.

Infinite sets $A$ and $B$ have the same size if and only if there exists a bijection $f: A \to B$. This means

- $f$ is injective (one-to-one) ($\forall x_0, x_1 \in A, (x_0 \neq x_1 \implies f(x_0) \neq f(x_1))$)
- $f$ is surjective (onto) ($\forall y \in B \exists x \in A, f(x) = y$)

If we are able to enumerate all elements in a set: $A = \{a_1, a_2, ..., a_i, ... \}$ (for all $i \in \mathbb{N}$), then $A$ has the same size as $\mathbb{N}$

- We call such sets **countably infinite**
- A set is **countable** if it is finite, or countably infinite
- The cardinality of $\mathbb{N}$ is $\aleph_0$

Some examples of countably infinite sets:

- $\mathbb{Z}$ (Integers)
- $\mathbb{N} \times \mathbb{N}$ (The set of pairs of natural numbers)
- $\mathbb{N}^k$ (The set of $k$-tuples of $\mathbb{N}$)
- $\mathbb{P}$ (The set of primes)
- $\mathbb{Q}$ (The set of rational numbers)
- $\Sigma^*$ (The set of all words over a finite alphabet $\Sigma$)
- The set of all Turing Machines

Some examples of uncountably infinite sets:

- $2^\mathbb{N}$ (The power set of natural numbers)
- $\mathbb{R}$ (The set of real numbers)
- $[0, 1]$ (The set of all real numbers between 0 and 1)

All the uncountable infinite sets have the same cardinality of $\aleph_1 = 2^{\aleph_0}$

- The continuum hypothesis asks if there exists some cardinality $\aleph_0 < X < \aleph_1$

Proofs for uncountably infinite sets use **Cantor's Diagonal Argument**. For example, we will prove that $2^\mathbb{N}$ is uncountably infinite

## Proof that $2^\mathbb{N}$ is Uncountably Infinite

Assume that $2^\mathbb{N}$ is countably infinite. This means we can enumerate **all** elements of $2^\mathbb{N}$ as such: $2^\mathbb{N} = \{A_1, A_2, ...\}$.

Now we define set $D = \{ i \ | \ i \in \mathbb{N}, i \not \in A_i \}$. We can see that $D \neq A_i$ for any $i$, because they all differ in at least 1 place. However, this means that we did not enumerate all the sets initially. Contradiction.

## Relevance to Recursively Enumerable Languages

There are uncountably many non-recursive languages

- The set of all possible languages is uncountable
- The set of all recursively-enumerable languages is countable

# Unrestricted Grammars

Compared to context-free grammars, now each production contains **context information**

$$
G = \begin{cases}
S \to aAbc \ | \ \Lambda \\
A \to aAbC \ | \ \Lambda \\
Cb \to bC \\
Cc \to cc
\end{cases}
$$

$G = \{ a^i b^i c^i \ | \ i \geq 0 \}$

Formal definition:

An unrestricted grammar $G$ is a tuple $(V, \Sigma, P, S)$, with

- $V$ is a set of variables
- $\Sigma$ is the finite input alphabet
- $P \subseteq (V \cup \Sigma)^+ \times (V \cup \Sigma)^*$, rules $\alpha \to \beta$ ($\alpha$ must contain a variable)
- $S \in V$ is the start symbol

## Example Grammar

The following grammar $G$ generates $\{ w[w] \ | \ w \in \{a, b\}^* \}$

- $V = \{ S, T, A, B \}$
- $\Sigma = \{a, b, [, ] \}$

Now we write our production rules

$$
G = \begin{cases}
S \to T[] \\
T \to aT[A \ | \ bT[B \ | \ [ \\
A] \to a] \\
B] \to b] \\
Aa \to aA \\
Ab \to bA \\
Ba \to aB \\
Bb \to bB
\end{cases}
$$

- $S$ and $T$ generate $\{w[W^R] \ | \ w \in \{a, b\}^*, W = \text{uppercase}(w)\}$
- Using rules $A] \to a]$ and $B] \to b]$, the rightmost $A$ or $B$ (The one next to $]$) will "materialize" and move left
- From right to left, each of the $A$ or $B$ will move all the way to the right, and "materialize" as well ($w[W^R]$ becomes $w[w]$)

# Turing Machines to Unrestricted Grammars

Unrestricted Grammars generate precisely recursively enumerable languages

1. For any TM $M$, there exists an equivalent unrestricted grammar $G_M$
2. For any unrestricted grammar $G$, there exists an equivalent TM $T_M$

Given TM $M$, construct grammar $G_M$ such that $\mathcal{L}(G_M) = \mathcal{L}(M)$. The idea for such a construction is split into 3 phases

1. Grammar rules to generate any word $w[q_0 \Delta w]$ from $S$
   - The first part of $w$ is the word that will be recognized
   - The last part $[q_0 \Delta w]$ represents the initial configuration of the TM
2. Grammar rules that simulate the functioning of $M$
   - For example, for all $q_i \xrightarrow{x/zR} q_j$, and for all $y \in \Gamma$, include a rule $q_ixy \to zq_jy$
3. Remove the final par $[...]$, but only if halt state $h_a$ is reached
   - This can be done with a number of simple erasure rules

$G_M$ generates $w$ iff TM $M$ accepts $w$

## Example

Turing Machine for the regular language $a^*b(a \cup b)^*$:

- We have states $q_0$ (initial), $q_1$, $h_a$
- $q_0 \xrightarrow{\Delta/\Delta R}q_1$
- $q_1 \xrightarrow{a/a R}q_1$
- $q_1 \xrightarrow{b / b R}h_a$

We have symbols of $G_M$:

- $\Sigma = \{a, b \}$
- $V = \{S, T, [, ], A, B, \Delta, q_0, q_1 h_a \}$

We split the grammar into 3 phases

1. Phase 1: Create $w[q_0 \Delta w]$
   - Note that $z \in \{a, b\}$
     $$
     \begin{aligned}
         S & \to T[] \\
         T[ & \to aT[A \ | \ bT[B \ | \ [q_0 \Delta \\
         A] & \to a] \\
         B] & \to b] \\
         Az & \to zA \\
         Bz & \to zB
     \end{aligned}
     $$
   - This was similar to the grammar $G = \{ w[w] \ | \ w \in \{a, b\}^*\}$
2. Phase 2: Simulate TM
   - Note that $z \in \{a, b, \Delta \}$
     $$
     \begin{aligned}
         q_0 \Delta z \to  \Delta q_1z \\
         q_1az \to aq_1z \\
         q_1bz \to bh_az \\
         q_0 \Delta ] \to  \Delta q_1 \Delta ] \\
         q_1a] \to aq_1 \Delta ] \\
         q_1b] \to bh_a \Delta ]
     \end{aligned}
     $$
3. Phase 3: Erase
   - We now have the string $w[X h_a Y]$ if the TM has accepted. We now remove the parts in the bracket, and are left with $w$
     $$
     \begin{aligned}
         h_a z → h_a  \\
         h_a ] → h_a  \\
         z h_a  → h_a  \\
         [h_a  → \Lambda
     \end{aligned}
     $$

For example, the derivation of $aaba$:

$$
\begin{aligned}
    S &\to^* aabaT[ABAA] \\
    &\to^* aaba[q_0 \Delta aaba] \\
    &\to^* aaba[\Delta aab h_a a] \\
    &\to^* aaba
\end{aligned}
$$

# From Unrestricted Grammar to Turing Machine

Given a grammar $G$, we will construct a TM $M$ such that $\mathcal{L}(M) = \mathcal{L}(G)$

We will create a non-deterministic 3-tape machine:

1. The input is written to tape 1
2. Encode the rules of $G$ onto tape 2; For example:

   - $S \to Abc \ | \ \Lambda \\ 
        A \to aAbC \ | \ \Lambda \\
        Cb \to bC \\
        Cc \to cc
    $
   - Encoded into the following string:

   $$
   \Delta S \Delta Abc \Delta \Delta S \Delta \Delta \Delta A \Delta aAbC \Delta \Delta A \Delta \Delta \Delta Cb \Delta bC \Delta \Delta Cc \Delta cc \Delta
   $$

3. Simulate the grammar using tape 3,
   - Start with writing the symbol $S$
   - Iteratively apply rules $u \to v$ on tape 2, non-deterministically chosen, to a partial word $u$ on tape 3, non-deterministically chosen
4. Terminate when contents of tape 1 and 3 are equal

$G$ generates word $w$ iff NTM $T_G$ has an accepting run

# Chomsky Hierarchy: A Classification of Languages

| Type   | Language               | Grammars          | Turing Machines         |
| ------ | ---------------------- | ----------------- | ----------------------- |
| Type 0 | Recursively enumerable | Unrestricted      | Turing Machines (N)TM   |
| ...    | Recursive              | ???               | Terminating TM          |
| Type 1 | Context-Sensitive      | Context-Sensitive | Linearly Bounded TM     |
| Type 2 | Context-Free           | Context-Free      | Pushdown Automata       |
| ...    | ???                    | Unambiguous       | ???                     |
| ...    | DCFL                   | ???               | Deterministic PDA       |
| Type 3 | Regular                | Regular           | Finite Automata (D/NFA) |

Fundamental tradeoffs:

- Powerful expressive formalisms can describe many languages
- Descriptions in simple formalisms can be analysed automatically

## Context-Sensitive Languages and Linearly Bounded TMs

A Context-Sensitive Language (CSL) is a grammar with only 1 restriction

- Every rule $\alpha \to \beta$ has $|\alpha| \leq |\beta|$
- This provides a bound on the max length of any derivation of a word $w$ to $2|w|$

A linarly-bounded TM (LBA) is a non-deterministic TM with only 1 restriction

- Only use the part of the tape occupied by the input word
- Using $kn$ cells for an input word of length $n$ is ok (multiple tracks)

Important results

- Context-Sensitive Grammars $\iff$ Linearly Bouned Automata
- Context-Sensitive Languages are recursive

The TM that decides a CSL stores the whole computation, which is finite

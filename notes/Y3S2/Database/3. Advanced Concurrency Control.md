# Advaned Concurrency Control

# Timestamp Protocol

Manage concurrency so that it is equivalent to serial execution in timestamp order

-   Each transaction is giving a timestamp when entering the system
-   Timestamps are an increasing integer sequence
-   Access to any data item must be in the order of timestamps

Protocol maintains 2 values for each item $X$

-   `read_TS(X)`: Timestamp of latest transaction to read item
-   `write_TS(X)`: Timestamp of latest transaction to write item

Note: The latest transaction is the youngest transaction, and has the largest timestamp

## Implementing Timestamp Protocol

Permit access to transactions following timestamps

-   When $T$ reads $X$, `write_TS(X)` must be earlier than the timestamp of $T$
-   When $T$ writes to $X$, `write_TS(X)` and `read_TS(X)` must be earlier
-   Abort $T$ if out of order, and restart $T$ with a newer timestamp

For reading:

```
if T >= write_TS(X):
    perform read
    read_TS(X) = max(T, read_TS(X))
else:
    abort
```

For writing:

```
if T >= write_TS(X) and T >= read_TS(X):
    perform write
    write_TS(X) = T
else:
    if T < read_TS(X):
        abort
```

Note that if `read_TS(X) <= T < write_TS(X)` means $T$ is already overwritten, hence we do nothing.

# Cascading Rollbacks

-   One transaction aborting can result in another transaction aborting
-   This occurs when transactions depend on each other, and read uncommitted data

How to eliminate cascading rollbacks?

-   Do not let transactions read "dirty" uncommitted data
-   No reading of data written by transactions which are not yet committed

# Strict Timestamp-based Concurrency Control

How to avoid cascading rollbacks?

-   Transactions should only read committed values

For reading:

```
if T >= write_TS(X):
    read_TS(X) = max(T, read_TS(X))
    wait for committed value of X
    perform read
else:
    abort
```

For writing:

```
if T >= write_TS(X) and T >= read_TS(X):
    write_TS(X) = T
    wait until X value is committed
    wait until all pending reads are done
    perform write
else:
    if T < read_TS(X):
        abort
```

# Cascading Rollback Terminology

Cascading rollback

-   Uncommitted transactions that read an item from an aborted transaction must be rolled back
-   These uncommitted transactions are working with the wrong value, hence need to restart and try again

Recoverable schedule

-   A schedule $S$ is recoverable if no transaction $T$ in $S$ commits until all other transactions $T'$ that have written an item that $T$ reads have committed
-   If $T$ reads item $X$, and transactions $T_2$ and $T_3$ write to $X$ as well, we must wait for $T_2$ and $T_3$ to commit, then we let $T$ commit
-   If $T$ commits before $T_2$ or $T_3$, and one of them rolls back, we cannot rollback $T$, because it is already committed

Cascadeless schedule

-   Every transaction reads only items that are written by committed transactions
-   Do not allow transactions to enter the situation with non-existing values (due to rollback)

Strict schedule

-   Transaction can neither read nor write to $X$ until the last transaction that wrote to $X$ has committed

# Multiversion Concurrency Control

Notice that read operations are sometimes rejected in concurrent processing, because an item has been overwritten by another operation

Key idea:

-   Maintain older versions of data
-   When reading, allocate the right version to the read operation of a transaction
-   This allows reads to never be rejected

Advantages and Disadvantages

-   Significantly more storage required to maintain multiple versions
-   To check unlimited growth of versions, garbage collection is run when old versions are no longer needed. This induces overhead in processing
-   In some cases, older versions are available for recovery for temporal databases (Full history is available)

## Multiversion Concurrency Based On Timestamp Ordering

-   When transaction $T$ reads a version of item $Q$, that version must be written by a transaction with an earlier timestamp than that of $T$ (and the oldest among all that qualify)
    -   Read the latest version of $Q$ before $T$ ran
-   When $T$ writes a version of $Q$, that version must not have been written or read by a transaction with a younger timestamp
    -   $Q$ should not have already been written by another transaction that is supposed to occur after $T$
    -   Else, $T$ is out of order (only occurs for write attempts)

## Multiversion Timestamps

Assume $X_1, ..., X_n$ are versions of item $X$ created by write operations on $X$

-   With each $X_i$, a `read_TS(X)` and a `write_TS(X)` are associated
-   `read_TS(Xi)`: The read timestamp of $X_i$, which is the largest timestamps of all transactions that have read $X_i$ (Most recent read)
-   `write_TS(Xi)`: The write timestamp of $X_i$ that wrote the value of version $X_i$ (the write that created this version)
-   Note that a new version of $X_i$ is created only by a write operation

## Rules in Multiversion Timestamps

To ensure serializability, 2 rules are used

1. Reject $T$ if it attempts to overwrite a version (with the most recent timestamp that is still earlier than $T$'s own timestamp) that was already read by a younger $T'$
    - If $T$ issues `write_item(X)` and version $X_i$ has the highest `write_TS(Xi)` of all versions of $X$ (most updated version), and is also less than or equal to `TS(T)` (only written by older transactions), but `read_TS(Xi) > TS(T)` (Read by a younger transaction), then abort and rollback.
    - Otherwise, create a new version $X_j$, and `read_TS(Xj) = write_TS(Xj) = TS(T)`
2. A read will never be rejected
    - If transaction $T$ issues `read_item(X)`, find the version $X_i$ that has the highest `write_TS(Xi)` of all versions of $X$ that is also less than equal to $TS(T)$ (Latest version before transaction occurred), then return the value of $X_i$ to $T$, and set the value of `read_TS(Xi) = max(read_TS(Xi), TS(T))`

# Certify Locks

Multiversion 2PL using certify locks

-   Allow a transaction $T'$ to read data item $X$ while it is write locked by transaction $T$
-   This is accomplished by maintaining 2 different versions of each data item $X$, where 1 version must always have been written by some committed transaction
-   The second "local version" is created when a transaction acquires a write lock
-   This means a write operation always creates a new version of $X$

There are now 3 modes of locks:

1. Read lock
2. Write lock - Now write locks are no longer fully exclusive, as we can read a data item while it is write-locked
3. Certify lock - New lock, which is fully exclusive

## Procedure of Using Certify Locks for Concurrency Control

1. $X$ is the committed version of the data
2. When $T$ wishes to write $X$, $T$ creates a second version $X'$ after obtaining a write lock on $X$
3. Other transactions continue to read $X$
4. When $T$ is ready to commit, it obtains a certify lock on $X'$
5. The committed version of $X$ becomes $X'$
6. $T$ releases its certify lock on $X$, which is the new value of $X$ now

## Lock Comptability Compared

In standard locking

-   If an item is read locked, we can grant more read locks. However, we cannot grant any write locks
-   If an item is write locked, we cannot grant any other locks

| ""    | Read | Write |
| ----- | ---- | ----- |
| Read  | Yes  | No    |
| Write | No   | No    |

In certify locking

-   If an item is read-locked, we can grant another read-lock, or another write-lock. However, we cannot grant a certify lock
-   If an item is write-locked, we can grant another read lock. However, we cannot have 2 write locks on the same item
-   If an item is certify-locked, we cannot grant any other lock

| ""      | Read | Write | Certify |
| ------- | ---- | ----- | ------- |
| Read    | Yes  | Yes   | No      |
| Write   | Yes  | No    | No      |
| Certify | No   | No    | No      |

## Pros and Cons

In multiversion 2PL certify locking:

-   Read and write operations from conflicting transactions can be processed concurrently (Increased concurrency)
-   But may delay transaction when it is ready to commit (have to obtain certify locks on all of its writes)
-   Avoids cascading aborts, but like strict 2PL scheme, conflicting transactions can become deadlocked

# Multiple Granularity Locking

Granularity of Data Items

-   A lockable unit of data defines its granularity
    -   Granularity can be coarse (entire database) or fine (a tuple or an attribute of a relation)
-   Data item granularity affects concurrency control performance
    -   Degree of concurrency is low for coarse granularity, but high for fine granularity
-   Examples of data item granularity
    -   A field of a database record (attribute of a tuple)
    -   A database record (a tuple or relation)
    -   A disk block
    -   An entire file
    -   The entire database

# Lock Hierarchy

To manage a lock hierarchy, in addition to reads and writes, three additional locking modes, called intention lock modes are defined

1. Intention-shared: Indicates that shared locks will be requested on some descendant node(s)
2. Intention-exclusive: Indicates that exclusive locks will be requested on some descendant node(s)
3. Shared-intention-exclusive: Indicates that the current node has a shared-lock, but exclusive locks will be requested on some descendant node(s)

## Lock Compatibility

| ""                         | Intention-Shared | Intention-Exclusive | Shared | Shared-Intention-Exclusive | Exclusive |
| -------------------------- | ---------------- | ------------------- | ------ | -------------------------- | --------- |
| Intention-Shared           | Y                | Y                   | Y      | Y                          | N         |
| Intention-Exclusive        | Y                | Y                   | N      | N                          | N         |
| Shared                     | Y                | N                   | Y      | N                          | N         |
| Shared-Intention-Exclusive | Y                | N                   | N      | N                          | N         |
| Exclusive                  | N                | N                   | N      | N                          | N         |

## Producing Serializable Schedules

The set of rules to adhere to to create serializable schedules using multiple granularity locking:

1. Lock compatibility must be adhered to
2. Root of the tree must be locked first, in any mode
3. A node $N$ can be locked by a transaction $T$ in S or IS mode only if the parent node is already locked by $T$ in either IS or IX mode
4. A node $N$ can be locked by $T$ in X, IX or SIX mode only if the parent of $N$ is already locked by $T$ in either IX or SIX mode
5. $T$ can lock a node only if it has not unlocked any other node (To enforce 2PL policy)
6. $T$ can unlock a node $N$ only if none of the children of $N$ are currently locked by $T$

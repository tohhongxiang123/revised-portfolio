# Query Evaluation

Query in High-level language

1. Scanning, parsing and semantic analysis
2. Query Optimisation
3. Query code generator
4. Runtime database processor

# Translating SQL Queries to Relational Algebra

Query in SQL is translated into relational algebra, which is then optimized

- Queries are decomposed into query blocks
  - A basic unit to be translated into algebraic operators to be optimized

A query block contains a single `SELECT-FROM-WHERE` expression, as well as `GROUP BY` or `HAVING` clauses (if present)

- Nested queries are identified as separate query blocks
- Aggregate operators in SQL must be included in the extended algebra
- Each query block is optimized

## Example Translation

```sql
SELECT LNAME, FNAME
FROM EMPLOYEE
WHERE SALARY > (
    SELECT MAX(SALARY)
    FROM EMPLOYEE
    WHERE DNO = 5
);
```

We have 2 query blocks:

```sql
SELECT LNAME, FNAME
FROM EMPLOYEE
WHERE SALARY > C;
```

This can be written as

$$
\Pi_{\text{LNAME, FNAME}} (\sigma_{\text{SALARY} > \text{C}} \text{EMPLOYEE})
$$

```sql
SELECT MAX(SALARY)
FROM EMPLOYEE
WHERE DNO = 5;
```

This can be written as

$$
\mathcal{F}_{\text{MAX SALARY}} (\sigma_{\text{DNO}=5}(\text{EMPLOYEE}))
$$

# Types of Selection Queries

1. Point query
   - Condition is on a single value
   - $\sigma_{\text{name = 'crisps'}}(\text{Product})$
2. Range
   - Condition is on a range of values
   - $\sigma_{1 < \text{price} < 4}(\text{Product})$
3. Conjunction
   - Combines 2 conditions with `AND`
   - $\sigma_{(\text{name = 'crisps'}) \land (1 < \text{price} < 4)}(\text{Product})$
4. Disjunction
   - Combines 2 conditions with `OR`
   - $\sigma_{(\text{name = 'crisps'}) \lor (1 < \text{price} < 4)}(\text{Product})$

# Executing Search for a Single Condition

Linear Search

- Retrieve every single record in the file, and test each record if it satisfies the selection condition

Binary Search

- If equality comparison on key attribute on which file is ordered, use binary search

Index-based Search

- If equality comparison is on a key attribute with primary index, use the index for index-based search
- If comparison condition is $<, \leq, >, \geq$ on key with primary index, use index-based search to find record satisfying corresponding **equality** condition, then retrieve all subsequent records in the file
- If equality comparison on non-key attribute with clustering index, use index-based serach

# Executing Conjunctions and Disjunctions

Conjunction

- If attributes involved in equality conditions in conjunctions match attributes in a composite index, use index directly
  - For example, if there is an index $(\text{Category}, \text{Product})$ for query $\sigma_{\text{Category = 'Dairy'} \land \text{Manufacturer = 'Arla'}} (\text{Product})$
- If some attribute involved in conjunctive condition has an index, use index to retrieve matching records, then check for each remaining simple condition in the conjunctive condition
  - If there is more than 1 option, pick the most selective one first (the one which is expected to return the fewest records)
  - E.g. for $\sigma_{\text{Category = 'Dairy'} \land \text{Manufacturer = 'Arla'}} (\text{Product})$, we would prefer to use the _Manufacturer_ index over _Category_, if we expect fewer products by "Arla" than overall dairy products
  - We can use the intersection of pointers in a secondary index as well (Like a B-tree)
    - Find list of pointers involving dairy
    - Find list of pointeres involving Arla
    - Retrieve data corresponding to the intersection of these pointers

# Join

Most time-consuming operation

- Often natural join or equijoin
- E.g. Customer \* Purchased

Join strategies

- Nested loop join (Brute force)
- Index-based join
- Sort-merge join
- Hash join

Strategies work on a per-block basis (not per record)

- Relation sizes and join selectivities also impact join cost

## Nested Loop

For each block in the outer table $R$

- Scan the entire inner table $S$
- For each entry in the inner table, test whether the record satisfies the join condition

Nested loop requires quadratic time

Note that the inner table should be the largest table

- Consider an outer relation with size $b_O$, inner relation with size $b_I$ and main memory of size $b_M$
- On the main memory, 1 block is used to read the outer relation, 1 block is used to read the inner relation. Hence the amount of buffers remaining is $b_M - 2$
- Outer: Read one block at a time, total $b_O$ operations
- Inner: For each outer block, read as much of the inner as possible $b_I / (b_M - 2)$. Total operations required is $b_O b_I / (b_M - 2)$
- Hence the total operations: $b_O + b_O b_I / (b_M - 2)$

## Index-Basd Join

Requires at least 1 index on a join attribute

- Single loop on the other relation $S$ (outer) to find the corresponding values for the indexed attribute in $R$ (inner)
- For each join value $S$, use index to retrieve matching records from $R$

## Algorithms for External Sorting

Sorting is a primary algorithm in query processing.

- Used when a `ORDER BY` is in the query
- Also used in joins

External sorting

- Sorting algorithms that are suitable for large files on disk that do not entirely fit into main memory, such as most database files

Sort-Merge strategy

- Start by sorting small subfiles (runs) of the main file, and then merge the sorted runs, creating a larger sorted subfile that are merged in turn
- Sorting phase $n_R = \lceil b / n_B \rceil$
- Merging phase: $d_M = \min(n_B - 1, n_R); n_P = \lceil \log_{d_M} (n_R) \rceil$
  - $n_R$: Number of initial runs
  - $b$: Number of file blocks
  - $n_B$: Available buffer space
  - $d_M$: Degree of merging
  - $n_P$: Number of passes

## Sort-Merge Join

Sort each relation using multiway merge-sort

Perform the most efficient join: Merge-join

- Copy pairs of blocks into memory in order, then scan both to find matches
- In this method, records of each file are scanned only once each for matching with the other file - unless both $A$ and $B$ are non-key attributes. In which case, the algorithm is slightly modified

## Hash Join

- Hash each relation on the join attributes
- Each bucket must be small enough to fit into memory
- Join corresponding buckets from each relation

# Other Operations

Projection: Straightforward

- If duplicate elimination is required, then this is done by sorting/hashing then scanning

Cartesian product

- Inherently expensive, need to generate all combinations of tuples
- Should be avoided if possible

Union/Intersection/Difference

- Sort and scan
- Hash into buckets, and then check each bucket

# Combining Operations with Pipelining

Motivation

- A query is mapped into a sequence of operations
- Each execution of an operation produces an intermediate result
- Generating and saving intermediate results is expensive and time-consuming

Alternative

- Avoid constructing intermediate results as much as possible
- Pipeline data through multiple operations: Pass result of previous operator to the next without waiting to complete the previous operation

For example:

$$
\Pi_{\text{LNAME, FNAME}} (\sigma_{\text{SALARY} > \text{C}} \text{EMPLOYEE})
$$

- Pass tuples from selection directly into projection
- Less space required, less time required (No need to store temporary relation to disk)

- For pipelining to be effective, use evaluation algorithms that generate output tuples while tuples are being received from inputs for the operation
- This is known as stream-based processing
- Pipelining may not always be possible, e.g. sort and hash-joins

# Aggregate Operations

`MIN`, `MAX`, `SUM`, `COUNT`, `AVG`

- Do table scan, maintain aggregate
  - E.g. replace min if smaller record found
- Use index
  - E.g. `SELECT MAX(SALARY) FROM EMPLOYEE`
  - If index on `SALARY`, traverse it for largest value, i.e. follow rightmost pointer from root to leaf

`SUM`, `COUNT`, `AVG`

- For a dense index (each record has 1 index entry)
  - Apply associated computation to the values in the index
- For a non-dense index,
  - Actual number of records associated with each index must be accounted for

`GROUP BY`

- Aggregate operator must be applied separately to each group of tuples
- Use sorting or hashing on one group attributes to partition to appropriate groups
- Compute aggregate for tuples in each group

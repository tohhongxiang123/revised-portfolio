# Syntax Analysis

A syntax analyser checks that a program is syntactically well-formed and transforms it from a sequence of tokens to an abstract syntax tree (AST)

-   The AST captures the structure of the program
-   In later stages, the compiler uses the AST for semantic analysis and code generation

# Context Free Grammar

Programming languages are recursive, and context free grammars are able to define recursive structures

-   A context free grammar is given by $G = (T, N, P, S)$
    -   A finite set of $T$ terminals
    -   A finite set $N$ of non terminals such that $T \cap N = \emptyset$
    -   A start symbol $S \in N$
    -   A finite set of rules $P$ in the form $A \to s_1 ... s_n$ where $A \in N, n \geq 0$, and $\forall i \in \{1, ..., n\}, s_i \in T \cup N$
        -   If $n = 0$, we write the rule as $A \to \lambda$

# Deriving Sentences

$\alpha \to^* \beta$ means that $\beta$ is derived from $\alpha$ in 0 or more steps

-   Since there are multiple rules for a nonterminal, we may derive many different sentences from the same initial phrase

The set of all terminal strings that are derivable from the start symbol $S$ is denoted by $L(G)$

If there are multiple non-terminals in a single sentence, we must choose which nonterminal to expand

-   A leftmost derivation expands from the left-most non-terminal
-   A rightmost derivation expands from the right-most non-terminal

# Parse Trees

A parse tree represents a derivation, and is used to show the structure of the sentence

-   Each node in a parse tree is labelled with a symbol
-   The root of the tree is the start symbol
-   Leaf nodes are labelled with terminal symbols or $\lambda$
-   Inner nodes are labelled with non-terminals

A parse tree is generated as follows:

-   A node labelled $A$ has children $s_1, ..., s_n$ iff there is a rule $A \to s_1 ... s_n$

# Ambiguous Grammar

A grammar is ambiguous if it has multiple distinct parse trees for the same sentence

# The Parsing Problem

Given a context-free grammar $G = (T, N, S, P)$ and a sentence $w \in T^*$, decide whether $w \in L(G)$

Top-down parsing: Generates a parse tree starting from $S$ and expand the tree by applying rules in a depth-first manner

Bottom-up parsing: Generates a parse tree starting from $w$ and working towards the root. A node is inserted into the tree only after the children have been inserted

## Top Down Parsing

Also known as:

1. Top-down, because it begins from the root of the tree
2. Predictive, because it predicts at each step which rule to use
3. LL(k), because it scans the input from left to right, producing a leftmost derivation, using $k$ symbols of lookahead. We only consider LL(1)
4. Recursive descent, because it can be implemented by a collection of mutually recursive procedures

## Recursive Descent Parsing

In a recursive descent parser, for every non-terminal $A$, there is a corresponding method `parseA` that can parse sentences derived from $A$

-   If the grammar has production rules for $S, C, A, B$, then we have the corresponding methods `parseS, parseC, parseA, parseB`

For a grammar

$$
G = \begin{cases}
    S &\to AC & \text{p1}\\
    C &\to c | & \text{p2} \\
        & \lambda & \text{p3} \\
    A &\to aBCd |  & \text{p4} \\
        & BQ & \text{p5} \\
    B &\to bB |  & \text{p6} \\
        & \lambda & \text{p7} \\
    Q &\to q |  & \text{p8} \\
        & \lambda & \text{p9}
\end{cases}
$$

We have parse rules:

```
parseS(ts)
{
    // ts is the input token stream
    if (ts.peek() in predict(p1))
        parseA(ts); parseC(ts);
    else /* syntax error */
}

parseA(ts)
{
    if (ts.peek() in predict(p4))
        match(a); parseB(ts);
        parseC(ts); match(d);
    else if (ts.peek() in predict(p5))
        parseB(ts); parseQ(ts);
}
```

-   `peek` examines the next input token without advancing the input
-   `match(t)` checks if `ts.peek() == t`

Recursive descent parsing

-   Start from the start symbol
-   If there is more than 1 rule for $A$, `parseA` inspects the next input token, and chooses a production rule among the rules of $A$ to apply
-   The code for applying a production rule is obtained by processing the right side of the rule, symbol by symbol $A \to X_1 \cdots X_n$
-   If the next symbol at $X_i$ is a terminal $t$, check whether the next input token is $t$
-   If it is a nonterminal $B$, continue recursively parsing $B$ using `parseB`
-   The code for applying a production rule $A \to \lambda$ will do nothing, and simply return

Recursive descent parsers use a lookahead of 1 token to determine which rule to use

-   Lookahead has to be nonambiguous - there should not be more than 1 rule for the same nonterminal whose RHS starts with the same token

A grammar which fulfills this condition is an $LL(1)$ grammar

-   A language for which there exists an $LL(1)$ grammar is an $LL(1)$ language

## Computing `predict(p)`

Consider a grammar rule $X \to X_1 \cdots X_m, m \geq 0$

-   The set of tokens that `predict(p)` returns includes
    -   The set of first tokens in sentences derivable from $X_1 \cdots X_m$
        -   The set of first tokens in $X_1$
        -   If $X_1$ is empty, the set of first tokens in $X_2$, and so on
        -   Note that if $m = 0$, the set is empty
    -   If $X_1 \cdots X_m$ is empty, the set of first tokens that may follow $X$

For example, $A \to BQ$

-   The set of first tokens in sentences that may be derived from $BQ$ is $\{b, q\}$
-   Because $BQ$ may be empty, the set of first tokens that may follow $A$ is $\{c, \$\}$

The set of tokens returned by `predict(p)` is `{b, q, c, $}`

For $A \to aBCd$, the set of tokens `predict(p)` returns is `{a}`

These `predict` calls determine which rule to use

To compute the set of tokens that predict rule p, we need to know

1. Whether a non-terminal can derive empty
2. The RHS of a rule can derive empty

2 boolean arrays are used

1. `symbolsDeriveEmpty[X]` for $X \in N$
2. `rulesDeriveEmpty[p]` for $p \in P$

For our grammar

$$
G = \begin{cases}
    S &\to AC & \text{p1}\\
    C &\to c | & \text{p2} \\
        & \lambda & \text{p3} \\
    A &\to aBCd |  & \text{p4} \\
        & BQ & \text{p5} \\
    B &\to bB |  & \text{p6} \\
        & \lambda & \text{p7} \\
    Q &\to q |  & \text{p8} \\
        & \lambda & \text{p9}
\end{cases}
$$

`symbolsDeriveEmpty`:

```
{
    S: true,
    C: true,
    A: true,
    B: true,
    Q: true
}
```

`rulesDeriveEmpty`:

```
{
    p1: true,
    p2: false,
    p3: true,
    p4: false,
    p5: true,
    p6: false,
    p7: true,
    p8: false,
    p9: true,
}
```

```
predict(p: X -> X1 X2 ... Xm) // returns a set of tokens
{
    ans = first(X1 X2 ... Xm);
    if ruleDerivesEmpty[p] then // whenX1 X2 ... Xm may be empty
        ans = ans âˆª follow(X);

    return ans;
}
```

`first(X1 X2 ... Xm)` returns the set of first tokens in sentences derivable from X1 X2 ... Xm . Formally:

$$
first(X_1 X_2 ... X_m) = {t \in T | \exists w \in T^*, [X_1 X_2 ... X_m \to^* t_w] }
$$

```
first(X1 X2 ... Xm) // returns a set of tokens
{
    for each nonterminal X in the language
    visitedFirst[X] = false;
    ans = internalFirst(X1 X2 ... Xm);
    return ans;
}
```

Main ideas for `internalFirst`:

-   If $X_1 ... X_m = \lambda$, there is no first token. Return $\emptyset$
-   if $X_1$ is a terminal symbol, the first token is this symbol. Return $\{X_1\}$. For example, `internalFirst(bB) = [b]`
-   If $X_1$ is a nonterminal
    -   `result = empty`
    -   if `visitedFirst[X1]` is false
        -   Set `visitedFirst[X1]` to true
        -   Look at every rule for `X1` and find the first tokens of each rule, and add to result
    -   If `symbolDerivesEmpty[X1]`, find the first token of `X2...Xm` and add to result
    -   Return result

## Computing `follow(X)`

`follow(X)` returns a set of tokens that can appear right behind the nonterminal $X$ in a phrase derived from the start symbol $S$. Formally

$$
\text{follow}(X) = \{ t \in T \ | \ \exists \alpha, \beta  \in (N \cup T)^*, [S \to^* \alpha X t \beta] \}
$$

```
follow(X) // returns a set of tokens that may follow X
{
    for each nonterminal Y in the language
        visitedFollow[Y] = false;

    ans = internalFollow(X);
    return ans;
}
```

Main idea for `internalFollow(X)`

1. If `visitedFollow[X] == true`, return $\emptyset$. Else
2. Set `visitedFollow[X]` to true
3. Find all occurrences of `X` in RHS
4. For each such occurrence, find the first tokens of the sequence after `X`. If the sequence after `X` may derive an empty string, call `internalFollow(LHS)` to find which tokens follow the LHS nonterminal
5. If `X` is the start symbol, add `$` to the result

# Obtaining LL(1) Grammars

-   LL(1) requires a unique combination of a nonterminal and a lookahead symbol to decide which rule to use
-   Two common categories of grammar rules make a grammar rule NOT LL(1)
    1. Common Prefixes
    2. Left recursion

## Common Prefixes

If the RHS of 2 rules for the same nonterminal starts with the same lookahead symbol, the grammar is not LL(1)

$$
G = \begin{cases}
    E \to N + E | N
\end{cases}
$$

One way to eliminate common prefixes is by introducing new nonterminals

$$
G = \begin{cases}
    E \to N E' \\
    E' \to + E | \lambda
\end{cases}
$$

## Left Recursion

If the RHS starts with the LHS nonterminal, it is left recursive, and the grammar is not LL(1)

$$
G = \begin{cases}
    E \to E f G | f
\end{cases}
$$

`predict(E)` would give the same result for both rules `[f]`

## Obtaining LL(1) Grammar

$$
    E \to E f G | G
$$

1. Change left recursion to right recursion

    $$
        E \to G f E | G
    $$

2. Remove common prefixes by introducing nonterminals

    $$
        G = \begin{cases}
            E \to G E' \\
            E' \to f E | \lambda
        \end{cases}
    $$

3. May want to remove mutual recursion (optional)

    $$
        G = \begin{cases}
            E \to G E' \\
            E' \to f G E' | \lambda
        \end{cases}
    $$

# Syntactic Error Recovery

-   A compiler should produce a useful set of diagnostic messages when presented with a faulty program
-   Semantic analysis and code generation will be disabled
-   After an error is detected, it is desirable to recover from it, and continue syntax analysis
-   In a simple form of error recovery, parser skips input until it finds a delimiter to end the parsing of the current nonterminal
-   The method for parsing a nonterminal is augmented with an extra parameter that is a set of delimiters

# Bottom Up Parsing

Generates a parse tree by starting at the leaves and working towards the root. A node is only inserted into the tree after the children have all been inserted.

-   Recursive descent (Top down) parsers are versatile and appropriate for a handwritten parser
-   Bottom up parsers are commonly used in the syntax analysis phase of a compiler because of its power, efficiency and ease of construction
-   Grammar features such as common prefixes and left recursion need to be addressed before top down parsing can be used. But these issues are not a problem for bottom up parsers

Bottom up parsing has a few names

-   Shift-reduce: The 2 main actions taken by a bottom-up parser is shifting symbols onto a parse stack, and reducing a string of such symbols at the top of the stack into the grammar's non terminals
-   LR(k) because it scans symbols from left to right, producing a rightmost derivation in reverse, using $k$ symbols of lookahead

# LR Parsing Engine

-   Parsing engine is driven by a table
-   It can also be described by a finite automaton
-   Table is indexed using the parser's current state and the next input symbol
-   At each step, engine looks up the table based on the current state and next input symbol for the action to take
-   Table entry indicates the action to perform (either shift or reduce) until the final action, which is to accept

# Classes of Bottom Up Parsers

All bottom up parsers use a single token of lookahead during parsing

-   They are finite automata with a stack
-   There are several methods of constructing the parse tables. The number indicates the number of lookahead tokens when building the parse tables
    -   LR(0): Simplest, but fails for many practical grammars
    -   LR(1): Quite general, can handle almost all practically interesting grammars
    -   LALR(1): Faster, slightly weaker version of LR(1), used by most bottom up parsers

# LR(0) Automata and Table Construction

-   Table construction process analyses the grammar
-   Each state corresponds to a row of the parser table
-   Each symbol in the terminal and nonterminal sets corresponds to a column of the table
-   During parsing, we keep track of where we are in the grammar
-   To do this, we use a marker "." in a grammar rule to show the current progress of the parser in recognising the RHS of the rule
-   Symbols before "." have already been seen. The first symbol after "." is what we expect next
    -   E -> . + E E
    -   E -> + . E E
    -   E -> + E . E
-   LR(0) table has a number of states
-   Each state consists of a number of LR(0) items
-   LR(0) items: An LR(0) item is a grammar rule with a marker "."
-   For an item $A \to \alpha \cdot \beta$, the item is called **initial** if $\alpha \to \lambda$ and final if $\beta \to \lambda$. A final item for the start symbol is called accepting
    -   An initial item: $Start \to \cdot S$
    -   A final item: $S \to A C \cdot$
    -   An initial item and a final item: $B \to \cdot \lambda$
-   Each LR(0) state is a set of LR(0) items, which is closed in the sense that if the state contains an item with a nonterminal $A$ immediately after the marker, we add the initial items for $A$ into the state. This is called the closure of the item

    -   Consider the grammar:

    $$
      G = \begin{cases}
          S \to A \\
          A \to aBd | BQ \\
          B \to b \\
          Q \to q
      \end{cases}
    $$

    -   For an item $S \to \cdot A$, since $A$ is the nonterminal immediately after the marker, we add all the initial items for $A$, which is $A \to \cdot aBd$ and $A \to \cdot BQ$. Since $B$ is also another non-terminal immediately following the marker, we also add $B \to \cdot b$ into the closure
    -   The final closure is $\{ S \to \cdot A, A \to \cdot a B d, A \to \cdot BQ, B \to \cdot b \}$

-   We describe the parsing process as a finite automaton
-   The start state is the closure of the initial items of the start symbol

    -   For the following grammar:

    $$
      G = \begin{cases}
          S \to E\$ \\
          E \to + EE | num
      \end{cases}
    $$

    -   There is only 1 item for the start symbol: $S \to \cdot E \$$
    -   Taking the closure, we get: $\{ S \to \cdot E \$, E \to \cdot +EE, E \to \cdot num \}$

-   For each symbol $\gamma$ that appearse to the right of the marker of an item (or items), we can **shift** over it and transition to a new state:
    -   Replace all items where $\gamma$ appearse to the right of the marker, by items where the marker follows $\gamma$
    -   Throw away all other items
    -   Take the closure of these items
-   Transitions are labelled by $\gamma$, which is either a terminal, or nonterminal
-   If there is a final item of the form $A \to \alpha \cdot$, we can **reduce**
-   An accepting state is one that contains a final item for the start symbol
-   The LR(0) automaton needs to be used together with a stack of states: This automaton is known as a pushdown automaton
-   The state of the parser is the state on top of the parser stack
-   Actions taken during bottom-up parsing are of 4 types
    1. shift(i): Consume the next input symbol, push state i on to the stack
    2. reduce($A \to \gamma$): Reduce by rule $A \to \gamma$, i.e., pop $|\gamma|$ states from the stack, and consider $A$ as the next input symbol
    3. accept: Report that input was parsed successfully
    4. error: Report a parse error
-   An LR(0) parse table is a compact representation of an LR(0) automaton
-   Rows are indexed by states, columns by symbols, cell in row $r$ and column $c$ contains a single parsing action to take when encountering input symbol $c$ in state $r$
-   Constructing a parse table from an LR(0) automaton is easy
    -   For every transition from a state $s$ to $s'$ labelled with a symbol $x$, enter shift(s') into the cell in row s, column x
    -   If state $s$ contains a final item $A \to \beta \cdot$, enter reduce($A \to \beta$) into all cells of row $s$
    -   For cell (0, StartSymbol), enter accept
    -   Enter error on any remaining empty cells

## Conflicts

-   Sometimes when trying to construct an LR(0) parse table, we end up with 2 different actions in the same cell; this is known as a conflict
-   There are 2 kinds of conflicts
    1. Shift-reduce conflict: Same cell contains both a shift and a reduce action
    2. Reduce-reduce conflict: The same cell contains 2 different reduce actions

### Shift-Reduce Conflict

If a state contains both a non-final item $A \to \beta \cdot \gamma$ (shift() action) and a final item $A \to \beta \cdot$ (reduce() action)

Shift-reduce conflicts may be eliminated by rewriting the grammar to remove same factors

For example:

$$
G = \begin{cases}
    S \to E\$ \\
    E \to num + E | num
\end{cases}
$$

This grammar has a shift-reduce conflict due to $E \to num + E | num$

-   $E \to num \cdot + E$ (a shift() action) and $E \to num \cdot$ (a reduce() action) in the same state

We rewrite the grammar:

$$
G = \begin{cases}
    S \to E\$ \\
    E \to E + num | num
\end{cases}
$$

Now we do not have a shift-reduce conflict

### Ambiguous Grammar

Ambiguous grammars always lead to conflict. Consider

$$
G = \begin{cases}
    S \to E \$ \\
    E \to E + E | num \\
\end{cases}
$$

This grammar is ambiguous due to the case of $num + num + num$

-   (num + num) + num
-   num + (num + num)

We will have to rewrite the grammar into a non-ambiguous one

# LALR(1): Look Ahead LR with 1 Token Lookahead

Due to its balance of power and efficicency, LALR(1) is the most popular LR table-building method

-   For every transition from state $s$ to $s'$ labelled with symbol $x$, enter shift(s') into cell in row s, column x
-   If state $s$ contains a final item $A \to \beta \cdot$, enter reduce($A \to \beta$) into the cells of row $s$ for each token $T \in itemFollow[(s, item)]$
-   For cell (0, StartSymbol), enter accept
-   Enter error into any remaining empty cells

We compute itemFollow[(s, item)] using a propagation graph

-   Consider an LR(0) transition graph
-   The pair (state, item) uniquely identifies each item
-   Each pair (state, item) is represented by a vertex in the LALR propagation graph
-   We compute itemFollow[] for each pair (state, item)
-   The LALR table is constructed with reference to the itemFollow[] computed for the items
-   Propagation graph will not be retained after constructing LALR table

## Generating the Propagation Graph

1. Setup
    1. Create the LR(0) finite automaton
    2. For each `(state, item)`, create a vertex `v` in the graph
    3. Initialise all `itemFollow[v]` to $\emptyset$
    4. Initialise `itemFollow[(0, StartSymbol Productions)] = {$}`
2. Build propagation graph
3. Propagate `itemFollow[]`

Note that an array `itemFollow` is used to store the itemFollow set for each vertex `v` in the propagation graph

## Building Propagation Graph Ideas

1. For each pair $(s, A \to \alpha \cdot B \gamma)$, put $first(\gamma)$ into the itemFollow set of $(s, B \to \cdot \delta)$
    - The result is the `token(s)` that follows $B$ is recorded in the itemFollow set of the initial item B
2. For each pair $(s, A \to \alpha \cdot X \gamma)$, a propagation edge is placed from $(s, A \to \alpha \cdot X \gamma)$ to $(t, A \to \alpha X \cdot \gamma)$
    - The result is, for each initial item in each state, we build a path that starts from the initial item to reach its final item
3. For each pair $(s, A \to \alpha \cdot B \gamma)$, when $\gamma \to^* \lambda$, place a propagation edge from $(s, A \to \alpha \cdot B \gamma)$ to $(s, B \to \cdot \delta)$
    - The result is, since $\gamma$ may be empty, we tell the initial item of $B$ that the tokens that may follow $B$ may come from the tokens following $A$

# Parser Generator Beaver

-   Beaver is a LALR(1) parser generator that generates parsers written in Java
-   LALR(1) parsers can accept grammar rules with left recursions and common prefixes
-   Beaver's syntax is similar to the notation we have been using for CFGs, except that Beaver uses `=` where we use $\to$
-   Rules for a nonterminal must be terminated by semicolon
-   The directive `%terminals` on the first line declares the set of terminals used by the grammar
-   The directive `%goal` specifies the start symbol
-   Beaver implicitly assumes that every name that is not declared to be a terminal is a non-terminal

Example of Beaver Specification

```
%terminals PLUS, MINUS, MUL, DIV, NUMBER, LPAREN, RPAREN;
%goal Expr;

Expr = Expr PLUS Term
    | Expr MINUS Term
    | Term
    ;

Term = Term MUL Factor
    | Term DIV Factor
    | Factor
    ;

Factor = NUMBER
    | LPAREN Expr RPAREN
    ;
```

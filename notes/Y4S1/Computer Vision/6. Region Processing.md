# Region Processing

Image regions are sets of pixels in an image that share common features
- Labels are assigned to pixels of different regions
- Regions may be encoded in a number of ways, such as labelled mask overlay and boundary encoding

# Region Properties

Mean: The average pixel gray-level/intensity

$$
\mu = \frac{1}{N} \sum_{(x, y) \in R} f(x, y)
$$

- $f(x, y)$ is the image value at coordinate $(x, y)$
- $R$ is the region
- $N$ is the total number of pixels in $R$

Variance: How different pixel gray-levels are to each other within a region

$$
\sigma^2 = \frac{1}{N} \sum_{(x, y) \in R} [f(x, y) - \mu]^2
$$

We can also compute these statistics from the image region histogram, since the histogram can be convferted directly into a probability density function (PDF) $p(r)$, where $r$ is the gray-value

$$
p(r) = h(r) / N
$$

From the PDF, we can calculate the mean $\mu$ and variance $\sigma^2$:

$$
\begin{aligned}
    \mu &= \sum_{r=0}^{255} r p(r) \\
    \sigma^2 &= \sum_{r=0}^{255} (r - \mu)^2 p(r)
\end{aligned}
$$

# Textures

Region homogeneity means not only similar intensity, but also similar intensity variation patterns, such as texture
- However it is hard to define/represent texture

![](https://www.researchgate.net/publication/313489901/figure/fig1/AS:459845661925383@1486647157804/The-full-Gabor-filter-bank-Each-square-has-a-width-of-100-ms-and-a-height-of-21-Bark.png)

To characterise textures, we use a large set of filters often known as a filter bank. The most popular is Gabor filters, that are characterised by frequency and orientation beyond spatial spread
- Gabor filters can be viewed as a sinusoidal signal of particular frequency and orientation, modulated by a Gaussian wave

$$
\begin{aligned}
    g(x, y; \lambda, \theta, \psi, \sigma, \gamma) &= \exp \left( - \frac{x'^2 + \gamma^2 y'^2}{2 \sigma^2} \right) \exp \left( i \left( 2 \pi \frac{x'}{\lambda} + \psi \right)\right) \\
    x' &= x \cos \theta + y \sin \theta \\
    y' &= -x \sin \theta + y \cos \theta
\end{aligned}
$$

- $\lambda$ controls the wavelength and frequency of the sinusoidal component, which governs the width of the stripes of the Gabor function. Increasing wavelength results in thicker stripes
- $\theta$: Controls the orientation of the Gabor function, the stripe is vertical when $\theta = 0$
- $\gamma$: Aspect ratio that controls the height of the Gabor function. The height becomes smaller when $\gamma$ is bigger
- $\sigma$: Bandwidth that controls the overall size of the Gabor envelope. For larger bandwidth, the envelope increases, allowing more stripes and vice versa

Gabor filters perform convolution to get filtered signals

![](https://d3i71xaburhd42.cloudfront.net/e4b40dfc59a7d7cb2e0ddc2622d5120f75a22f02/2-Figure3-1.png)

Filter outputs can be concatenated to form a texture feature vector for each pixel. For example, for a filter bank with 4 filters:

$$
\tau(x, y) = \begin{bmatrix}
    \sum_u \sum_v |g_1(x + u, y + v)| \\
    \sum_u \sum_v |g_2(x + u, y + v)| \\
    \sum_u \sum_v |g_3(x + u, y + v)| \\
    \sum_u \sum_v |g_4(x + u, y + v)|
\end{bmatrix}
$$

$g_k = f * h_k$, we convolve the image with the $k$-th filter

# Region Segmentation

## Simple Thresholding

Applies to any region properties represented by a scalar: E.g. segmenting an image into 2 regions with different gray-levels

$$
s = \begin{cases}
    0 & r \leq t \\
    1 & r > t
\end{cases}
$$

- $s$ is the binary overaly intensity
- $r$ is the original gray-level intensity
- $t$ is the threshold
- Useful when segmenting foreground object which contains higher or lower-gray levels compared to the background

Simple thresholding applies when image histogram is clearly bimodal (2 distinct modes)

We can threshold at either
- Middle fo the dynamic range (127 for 0-255)
- Thresholding at average pixel value

## Otsu Algorithm

Otsu's global thresholding algorithm works with the intuition:
- Threshold divides pixels into 2 classes: Pixels higher or lower than the threshold
- Pixels within each class should have similar gray-levels
- Pixels belonging to different classes should have different gray-levels

Mathematically:
- Minimise intra-class variance
- Maximise inter-class variance

Intra-class variance is defined as:

$$
\sigma_w^2 = q_L(t) \sigma_L^2(t) + q_H(t) \sigma_H^2(t)
$$

- $t$ is the threshold
- The upper group probability $q_H(t)$ and lower group probability $q_L(t)$ are defined by:

    $$
        q_L(t) = \sum_{r=0}^{t} p(r) \\
        q_H(t) = \sum_{r = t + 1}^{255} p(r)
    $$
- The upper group mean $\mu_H(t)$ and lower group mean $\mu_L(t)$ are defined by:

    $$
        \mu_L(t) = \frac{1}{q_L(t)} \sum_{r=0}^{t} r p(r) \\ 
        \mu_H(t) = \frac{1}{q_H(t)} \sum_{r = t + 1}^{255} r p(r)
    $$
- The upper group variance $\sigma_H^2(t)$ and lower group variance $\sigma_L^2(t)$ are defined by:

    $$
        \sigma_L^2(t) = \frac{1}{q_L(t)} \sum_{r=0}^{t} (r - \mu_L(t))^2 p(r) \\
        \sigma_H^2(t) = \frac{1}{q_H(t)} \sum_{r=0}^{t} (r - \mu_H(t))^2 p(r) \\
    $$

A straightforward application of the Otsu method involves computing $\sigma_w^2(t)$ for $t = 1, ..., 254$, and selecting the $t$ with the smallest $\sigma_w^2$

The inter-class variation $\sigma_b^2(t)$ can be derived by:

$$
\begin{aligned}
    \sigma_b^2(t) &= \sigma^2 - \sigma_w^2(t) \\
    &= \omega_0 (\mu_0 - \mu_T)^2 + \omega_1(\mu_1 - \mu_T)^2 \\
    &= \omega_0(t) \omega_1(t) [\mu_0(t) - \mu_1(t)]
\end{aligned}
$$

- $\sigma^2$ is the variance of the entire image
- Recall that $\sigma_w^2(t)$ is the intra-class variantion
- $\omega_0 = q_L(t), \omega_1 = q_H(t)$
- $\mu_T$ is the mean of the entire image

## K-Means Clustering

Limitation of simple thresholding
- There may be more than 2 image regions to segment
- Texture feature vectors contain multiple values (multiple dimensions) - cannot specify a single threshold

Clustering is to classify different classes represented by feature vectors

We measure euclidean distance in feature vector space

$$
D(\bold{\tau}_1, \bold{\tau}_2) = \lVert \bold{\tau}_1 - \bold{\tau}_2 \rVert
$$

In K-means clustering,
- Intra-cluster distances (distances within clusters) are minimised
- Inter-cluster distances (distances between clusters) are maximised

Procedure for $K$-means clustering:
1. We initialise parameter $k$, and $k$ cluster seeds $m_1^{(1)}, ..., m_k^{(1)}$
    - $m_j^{(i)}$ is the centroid of cluster $j$ at timestep $i$
2. Assign each sample to the nearest cluster:

    $$
        S_i^{(t)} = \{ x_p: \lVert x_p - m_i^{(t)} \rVert^2 \leq \lVert x_p - m_j^{(t)} \rVert^2 \forall j, 1 \leq j \leq k \}
    $$
3. Calculate the new means of all new clusters

    $$
        m_i^{(t + 1)} = \frac{1}{|S_i^{(t)}|} \sum_{x_j \in S_i^{(t)}} x_j
    $$

K-means clustering can be combined with a filter bank for segmenting highly-textured regions

# Semantic Segmentation

An image is just a collection of pixels. Semantic segmentation classifies each image pixel to a semantic class. It can be thought of as a classification problem per pixel

There are 3 types of segmentation techniques:
- Semantic segmentation
  - Assigns each image pixel a semantic class label
- Instance segmentation
  - Labels each object instance pixels. Identifies instances on top of semantic segmentation
  - Not to be confused with object detection. Object detection produces rectangular boxes. Instance segmentation produces exact object boundary
  - Instance segmentation does not care about image background
- Panoptic segmentation
  - Combination of semantic and instance segmentation
  - Semantic segmentation classifies all pixels but has no instance information
  - Instance segmentation has instance information but discards background information
  - Panoptic segmentation captures both

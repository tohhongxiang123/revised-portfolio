# Overview of Bayesian Classifiers

# Uncertainty in Prediction

In many applications, the mapping between input features and output labels is non-deterministic (uncertain)

# Bayesian Classifiers

-   From a probability viewpoint, the mapping $f: x \to y$ can be modelled as a conditional probability $P(y | x)$
-   Bayesian classifiers aim to learn the mapping $f: x \to y$ for supervised learning in the form of conditional probability $P(y | x)$, such that for any input $x^*$, one can use $P(y = c | x^*)$ to predict the probability of $x^*$ belonging to class $c$ where $c \in \{0, ..., C-1\}$
-   How to estimate $P(y = c | x^*)$ for different classes?
-   How to make use of $P(y = c | x^*)$ to make predictions?

# Marginal Probability

-   Let $A$ be a random variable (an input feature/class label)
-   Marginal probability $0 \leq P(A = a) \leq 1$ refers to the probability that $A = a$
-   $\sum_{a_i} P(A = a_i) = 1$ (The total probability of $A$ being any number should be 1)

# Joint Probability

-   Let $A$ and $B$ be a pair of random variables (features/labels)
-   Their joint probability is $P(A = a, B = b)$ refers to the probability that $A = a$ **and** $B = b$

# Conditional Probability

-   $P(B = b | A = a)$ refers to the probability that $B = b$ given that $A$ is observed to have the value $a$
-   $\sum_{b_i} P(B = b_i | A = a) = 1$

# Sum Rule

-   The connection between joint probability of $A$ and $B$ and the marginal probability of $A$:

$$
P(A = a) = \sum_{b_i} P(A = a, B = b_i) \\
P(A) = \sum_{B} P(A, B) \\
P(A = a) = \sum_{c_j} \sum_{b_i} P(A = a, B = b_i, C = c_j) \\
P(A) = \sum_{C} \sum_{B} P(A, B, C)
$$

# Product Rule

-   The connection between joint, marginal and conditional probabilities for $A$ and $B$:

$$
\begin{aligned}
P(A = a, B = b) &= P(B = b | A = a) \times P(A = a) \\
&= P(A = a | B = b) \times P(B = b) \\

P(A, B) &= P(B | A) P(A) = P(A | B) P(B)
\end{aligned}
$$

# Bayes Theorem

$$
P(A | B) = \frac{P(A, B)}{P(B)} = \frac{P(B | A) P(A)}{P(B)}
$$

For the generalised form where $A$ and $B$ are sets:

$$
\begin{aligned}
P(A_1, ..., A_k | B_1, ..., B_p) &= \frac{P(A_1, ..., A_k, B_1, ..., B_p)}{P(B_1, ..., B_p)} \\
&= \frac{P(B_1, ..., B_p | A_1, ..., A_k) P(A_1, ..., A_k)}{P(B_1, ..., B_p)}
\end{aligned}
$$

-   $P(y | x)$ is the posterior
-   $P(y)$ is the prior
-   Prior probability represents what is **originally believed before new evidence is introduced**, and posterior probability **takes this new information into account**

A Bayesian Classifier makes a prediction based on the maximum posterior:

$$
\begin{aligned}
y^* = c^* \text{ if } c^* &= \argmax_c P(y = c | x^*) \\
&= \argmax_c \frac{P(x^* | y = c) P(y = c)}{P(x^*)} \\
&= \argmax_c P(x^* | y) P(y = c)
\end{aligned}
$$

# Naive Bayes Classifier

How to estimate $P(x | y = c)$ from the training data?

-   Assume that features are conditionally independent given the class labels

For some $x = [x_1, ..., x_d] \in \mathbb{R}^d$

$$
\begin{aligned}
P(x | y = c) = \prod_{i=1}^{d} P(x_i | y = c)
\end{aligned}
$$

# Bayesian Belief Network

A more general approach to modelling the independence and conditional independence among $x$ and $y$ such that the computation of $P(x, y) = P(x | y) P(y)$ is tractable

-   Use graphical representation of probabilistic relationships among features ($x$) and output class ($y$)

# Decisions with Posteriors: Limitations

By far, a decision is made based on the maximum posterior

-   Cost of misclassification of different classes is not taken into consideration
-   However in some domains, such as the medical domain, the cost of misclassification on different classes may be different
-   Cost of misclassifying a healthy patient with Covid19: Stay in home/hospital for quarantine
-   Cost of misclassifying a covid patient as healthy: Community outbreak

# Loss/Cost

-   Actions $a_c$ (i.e. predict $y = c$), where $c = 0, ..., C - 1$
-   Define $\lambda_{ij}$ as the loss/cost of $a_i$ where the optimal action is $a_j$ (Predict $y = i$ while the true label is $y = j$)

For example, let us say that $y = 0$ is healthy, and $y = 1$ is covid-positive. Based on a trained Bayesian classifier, we know that $P(y = 1 | x) = 0.1$. Let us define the costs each possible action:

-   $\lambda_{00} = 0$: Correct prediction
-   $\lambda_{01} = 10$: Misclassified a covid-positive patient as healthy
-   $\lambda_{10} = 1$: Missclassified a healthy patient as covid-positive
-   $\lambda_{11} = 0$: Correct prediction

The expected risk for taking action $a_i$:

$$
R(a_i  | x) = \sum_{c = 0}^{C - 1} \lambda_{ic} P(y = c | x)
$$

-   To estimate the risk of an action, we consider all possible losses
-   Taking action $a_i$, we need to consider all the losses $\lambda_{i0}, \lambda_{i1}, ..., \lambda_{i(C - 1)}$
-   The possibilities of each loss occurring is weighted based on how likely it is to occur. Hence we use the weighted sum $P(y = c | x)$ as a weight for each loss $\lambda_{ic}$, and compute the weighted sum of all possible losses (expected risk)

Considering the risks from above, we can calculate:

1. The expected risk of taking action $a_0$ (classifying a patient as healthy)

$$
R(a_0 | x) = \lambda_{00} P(y = 0 | x) + \lambda_{01} P(y = 1 | x) = 1
$$

2. The expected risk of taking action $a_1$ (classifying a patient as covid-positive)

$$
R(a_1 | x) = \lambda_{10} P(y = 0 | x) + \lambda_{11} P(y = 1 | x)
$$

# Decision Based on Expected Risk

Now, instead of choosing an action based on the highest probability, we want to choose an action with the lowest risk

$$
a^* \text{ if } a^* = \argmin_{a_c} R(a_c | x)
$$

In our previous covid-19 example, since $R(a_1 | x) < R(a_0 | x)$, we predict that patient more likely has covid-19

# Special Case

-   Making predictions based on maximum posterior is a special case of making decisions with minimal risk
-   Define losses as

$$
\lambda_{ij} = \begin{cases}
0 \text{ if } i = j \\
1 \text{ if } i \neq j
\end{cases}
$$

This is known as 0/1 loss. Now, the risk of taking action $a_i$ is

$$
\begin{aligned}
R(a_i | x) &= \sum_{c = 0}^{C - 1} \lambda_{ic} P(y = c | x) \\
&= \lambda_{i0} P(y = 0 | x) + ... + \lambda_{(i - 1)i} P(y = i - 1 | x) + \lambda_{ii} P(y = i | x) + \lambda_{(i + 1)i} P(y = i + 1 | x) + \\ & ... + \lambda_{i(C - 1)} P(y = C - 1 | x) \\
&= \lambda_{i0} P(y = 0 | x) + ... + \lambda_{(i - 1)i} P(y = i - 1 | x) + \lambda_{(i + 1)i} P(y = i + 1 | x) + ... + \lambda_{i(C - 1)} P(y = C - 1 | x) \\
&= P(y = 0 | x) + ... + P(y = i - 1 | x) + P(y = i + 1 | x) + ... + P(y = C - 1 | x) \\
&= 1 - P(y = i | x)
\end{aligned}
$$

Since $R(a_i | x) = 1 - P(y = c | x)$, the minimum risk occurs when $P(y = c | x)$ is the largest, which corresponds to the maximum posterior

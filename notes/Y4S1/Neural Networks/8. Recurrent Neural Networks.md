# Recurrent Neural Networks (RNN)

Designed to process sequential information

-   Next data point is dependent on current data point
-   E.g. NLP, genomic sequences etc.

RNN attempts to capture dependencies among data points in the sequence

![](https://media.geeksforgeeks.org/wp-content/uploads/20230518134831/What-is-Recurrent-Neural-Network.webp)

-   $h$: Hidden state, a memory that captures information about what has been processed so far

# Types of RNNs

![](https://www.researchgate.net/publication/344570387/figure/fig3/AS:960025010917394@1605899207869/Elman-left-side-picture-and-Jordan-network-right-side-picture-models-25.png)

-   Elman (Vanilla RNN): Current hidden state depends on **previous hidden state**
-   Jordan: Current hidden state depends on **previous output**

# RNN with Hidden Recurrence

![](RNN-Elman.png)

Assume the RNN takes in inputs $\bold{x} \in \mathbb{R}^n$, has a hidden dimension $\bold{h} \in \mathbb{R}^d$, and has output $\bold{y} \in \mathbb{R}^m$

The parameters of an RNN:

-   $\bold{U} \in \mathbb{R}^{n \times d}$: Weight vector that transforms raw inputs to hidden layer
-   $\bold{W} \in \mathbb{R}^{d \times d}$: Recurrent weight vector connecting previous hidden layer output to hidden input
-   $\bold{b} \in \mathbb{R}^{d}$: Bias connected from previous hidden layer to hidden layer
-   $\bold{V} \in \mathbb{R}^{d \times m}$: Weight vector of output layer
-   $\bold{c} \in \mathbb{R}^{m}$: Bias connected to output layer
-   $\phi$: The $\tanh$ hidden-layer activation function
-   $\sigma$: The linear/softmax output-layer activation function

## Single Inputs

Let $\bold{x}(t), \bold{y}(t), \bold{h}(t)$ be the input, output and hidden output of the network at time $t$. Note that $\bold{h}(0) = \hat{0}$

Activations of the Elman-type RNN with 1 hidden layer is given by:

$$
\begin{aligned}
    \bold{h}(t) &= \phi(\bold{U}^T \bold{x}(t) + \bold{W}^T \bold{h}(t - 1) + \bold{b}) \\
    \bold{y}(t) &= \sigma(\bold{V}^T \bold{h}(t) + \bold{c})
\end{aligned}
$$

Note that $\sigma$ is a softmax function for classification, and a linear function for regression

## Batch Inputs

Given $P$ patterns $\{ \bold{x}_p \}_{p=1}^{P}$ where $\bold{x}_p = (\bold{x}_p(t))_{t=1}^{T}$,

$$
\bold{X}(t) = \begin{pmatrix}
    \bold{x}_1(t)^T \\ \vdots \\ \bold{x}_P(t)^T
\end{pmatrix}
$$

Let $\bold{X}(t), \bold{Y}(t), \bold{H}(t)$ be the batch input, output and hidden output of the network at time $t$. Note that $\bold{H}(0) = \hat{0}$

Activation of the Elman type RNN is given by

$$
\begin{aligned}
    \bold{H}(t) &= \phi(\bold{X}(t) \bold{U} + \bold{H}(t - 1) \bold{W} + \bold{B}) \\
    \bold{Y}(t) &= \sigma(\bold{H}(t) \bold{V} + \bold{C})
\end{aligned}
$$

# RNN with Top-Down Recurrence (Jordan)

![](RNN-Jordan.png)

The hidden layer takes the previous output $\bold{y}(t-1)$ (instead of the previous hidden-layer output). Note that the dimensions of $\bold{W} \in \mathbb{R}^{m \times d}$ instead

## Single Input

Let $\bold{x}(t), \bold{y}(t), \bold{h}(t)$ be the input, output and hidden output of the network at time $t$. Note that $\bold{h}(0) = \hat{0}$

$$
\begin{aligned}
    \bold{h}(t) &= \phi(\bold{U}^T \bold{x}(t) + \bold{W}^T \bold{y}(t - 1) + \bold{b}) \\
    \bold{y}(t) &= \sigma(\bold{V}^T \bold{h}(t) + \bold{c})
\end{aligned}
$$

## Batch Input

Let $\bold{X}(t), \bold{Y}(t), \bold{H}(t)$ be the batch input, output and hidden output of the network at time $t$. Note that $\bold{H}(0) = \hat{0}$

$$
\begin{aligned}
    \bold{H}(t) &= \phi(\bold{X}(t) \bold{U} + \bold{Y}(t - 1) \bold{W} + \bold{B}) \\
    \bold{Y}(t) &= \sigma(\bold{H}(t) \bold{V} + \bold{C})
\end{aligned}
$$

# Backpropagation Through Time (BPTT)

Consider the vanilla-RNN with hidden recurrence. Forward propagation equations:

$$
\begin{aligned}
    \bold{h}(t) &= \phi(\bold{U}^T \bold{x}(t) + \bold{W}^T \bold{h}(t - 1) + \bold{b}) = f(\bold{x}(t), \bold{h}(t-1), \bold{W}) \\
    \bold{u}(t) &= \sigma(\bold{V}^T \bold{h}(t) + \bold{c}) \\
    \bold{y}(t) &= \begin{cases}
        \text{softmax}(\bold{u}(t)) & \text{ Classification} \\
        \bold{u}(t) & \text{ Linear}
    \end{cases} \\
    &= g(\bold{h}(t), \bold{V})
\end{aligned}
$$

We have learnable parameters

-   $\bold{U}$: Weights from input to hidden
-   $\bold{W}$: Weights from previous hidden to hidden
-   $\bold{V}$: Weights from hidden to output
-   $\bold{b}$: Bias from previous hidden to hidden
-   $\bold{c}$: Bias from hidden to output

For backpropagation, the gradients propagate backwards, starting from the end of the sequence, in 2 directions

1. Top down (from output down to input)
2. Reverse sequence direction (from $t = T$ to $t = 0$)

Consider some loss function $J(t) = l(\bold{y}(t), \hat{\bold{y}}(t))$ for inputs at a specific timestep $t$ (Cross-entropy for classification, MSE for linear regression)

-   $\bold{y}(t)$ is our target at timestep $t$
-   $\hat{\bold{y}}(t)$ is our prediction at timestep $t$

We take the average of the gradients of the loss function through time

$$
\begin{aligned}
    \frac{\partial J}{\partial \bold{W}} &= \frac{1}{T} \sum_{t=1}^{T} \frac{\partial J(t)}{\partial \bold{W}} \\
    &= \frac{1}{T} \sum_{t=1}^{T} \frac{\partial J(t)}{\partial \bold{u}(t)} \frac{\partial \bold{u}(t)}{\partial \bold{h}(t)} \frac{\partial \bold{h}(t)}{\partial \bold{W}}
\end{aligned}
$$

$\frac{\partial J(t)}{\partial \bold{u}(t)}$ and $\frac{\partial \bold{u}(t)}{\partial \bold{h}(t)}$ are easy to compute, but $\frac{\partial \bold{h}(t)}{\partial \bold{W}}$ has to be computed recurrently, since $\bold{h}(t)$ is a recurrent term. $\bold{h}(t)$ depends on both $\bold{h}(t - 1)$ and $\bold{W}$. Thus, evaluating the total derivate of $\bold{h}(t)$ using the chain rule:

$$
\frac{\partial \bold{h}(t)}{\partial \bold{W}} = \frac{\partial f(\bold{x}(t), \bold{h}(t-1), \bold{W})}{\partial \bold{W}} + \frac{\partial f(\bold{x}(t), \bold{h}(t-1), \bold{W})}{\partial \bold{h}(t-1)} \frac{\partial \bold{h}(t - 1)}{\partial \bold{W}}
$$

To find the above gradient, assume we have 3 sequences $\{a_t\}, \{b_t\}, \{c_t\}$ satisfying $a_0 = 0$ and $a_t = b_t + c_t a_{t-1}$ for $t = 1, 2, ...$. Then for $t \geq 1$, we can prove that

$$
    a_t = b_t + \sum_{i=1}^{t - 1} \left( \prod_{j=i+1}^{t} c_j \right) b_i
$$

By substituting $a_t, b_t, c_t$ according to

$$
\begin{aligned}
    a_t &= \frac{\partial \bold{h}(t)}{\partial \bold{W}} \\
    b_t &= \frac{\partial f(\bold{x}(t), \bold{h}(t-1), \bold{W})}{\partial \bold{W}} \\
    c_t &= \frac{\partial f(\bold{x}(t), \bold{h}(t-1), \bold{W})}{\partial \bold{h}(t-1)}
\end{aligned}
$$

the gradient computation satisfies $a_t = b_t + c_t a_{t-1}$. Hence, we have a closed-form solution

$$
\frac{\partial \bold{h}(t)}{\partial \bold{W}} = \frac{\partial f(\bold{x}(t), \bold{h}(t-1), \bold{W})}{\partial \bold{W}} + \sum_{i=1}^{t-1} \left( \prod_{j = i + 1}^{t} \frac{\partial f(\bold{x}(j), \bold{h}(j - 1), \bold{W})}{\partial \bold{h}(j - 1)} \right) \frac{\partial f(\bold{x}(i), \bold{h}(i - 1), \bold{W})}{\partial \bold{W}}
$$

Runtime is $O(T)$, where $T$ is the length of the input sequence, and cannot be reduced by parallelisation due to its sequential nature.

Also note,

![](rnn-backprop.png)

$$
\begin{aligned}
\nabla_{\bold{h}(t)} J &= \left( \frac{\partial \bold{h}(t + 1)}{\partial \bold{h}(t)} \right)^T \nabla_{\bold{h}(t + 1)} J + \left( \frac{\partial \bold{u}(t)}{\partial \bold{h}(t)} \right)^T \nabla_{\bold{u}(t)} J \\
&= \bold{W} \text{diag}(1 - \bold{h}^2(t + 1)) \nabla_{\bold{h}(t + 1)} J + \bold{V} \nabla_{\bold{u}(t)} J
\end{aligned}
$$

1. The first term is the gradient that is backpropagated due to the future hidden state. $\frac{d}{dx} \tanh(x) = 1 - \tanh^2(x)$. $\bold{W}$ is the weights in the current hidden layer, and $\nabla_{\bold{h}(t + 1)} J$ is the gradient from the future hidden layer
2. The second term is the gradient that is backpropagated due to the output

# Long Short-Term Memory (LSTM)

RNNs have difficulties in learning long range dependencies due to exploding/vanishing gradients

-   During gradient back-propagation learning of RNN, gradients are multiplied by a large/small number many times, which could cause the gradient to explode/vanish
-   Exploding gradients cause learning to diverge
    -   Can be solved by **gradient clipping**
-   Vanishing gradients cause learning to stop

## Gradient Clipping

Commonly, we use 2 methods:

1. Clip gradient $g$ if it exceeds a threshold
    $$
        \text{If } \lVert g \rVert > v \implies \lVert g \rVert \leftarrow v
    $$
2. Normalise the gradient when it exceeds a threshold
    $$
        \text{If } \lVert g \rVert > v \implies \lVert g \rVert \leftarrow \frac{g}{\lVert g \rVert} v
    $$

For vanishing gradients, the solution is a Gated RNN

-   Long short-term memory (LSTM)
-   Gated Recurrent Units (GRU)

## LSTM Units

![](lstm.png)

The key of LSTM is "state"

-   A persistent module called the cell state $\bold{c}(t)$
-   State is a representation of past history

The LSTM is made up of 3 gates

1. Forget gate
2. Input gate
3. Output gate

### Forget Gate

Given the current input, determine how much of the previous state the cell should remember

$$
\bold{f}(t) = \sigma \left( \bold{U}_f^T \bold{x}(t) + \bold{W}_f^T \bold{h}(t - 1) + \bold{b}_f \right)
$$

-   For e.g., we want to predict the next word based on all the previous words. Cell state may include gender of present subject, so that proper nouns can be used. When we see a new subject, we want to forget the old subject

### Input gate

Allow incoming signal to alter the state of the memory cell, or block the incoming signal. Decides what new information to store in the cell stage. Input gate consists of 2 parts:

1. Sigmoid input gate, decides which values to update
2. $\tanh$ layer, creates a vector of new candidate values $\tilde{\bold{c}}(t)$ that could be added to the state

$$
\begin{aligned}
    \bold{i}(t) &= \sigma \left( \bold{U}_i^T \bold{x}(t) + \bold{W}_i^T \bold{h}(t - 1) + \bold{b}_i \right) \\
    \tilde{\bold{c}}(t) &= \phi \left( \bold{U}_c^T \bold{x}(t) + \bold{W}_c^T \bold{h}(t - 1) + \bold{b}_c \right)
\end{aligned}
$$

-   E.g., for language modelling, we would like to add the gender of the new subject to the cell state to replace the old one we are forgetting

Now our overall cell state:

$$
\bold{c}(t) = \tilde{\bold{c}}(t) \odot \bold{i}(t) + \bold{c}(t - 1) \odot \bold{f}(t)
$$

-   $\tilde{\bold{c}}(t)$: Our new candidate vector to add to the cell state
-   $\bold{i}(t)$: Which values to update in the cell state
-   $\bold{f}(t)$: How much of our old cell state to forget
-   Note that $\odot$ represents element-wise multiplication

### Output Gate

Output gate allows the state of the memory cell to have an effect on other neurons, or prevent it

$$
\begin{aligned}
    \bold{o}(t) &= \sigma \left( \bold{U}_o^T \bold{x}(t) + \bold{W}_o^T \bold{h}(t - 1) + \bold{b}_o \right) \\
    \bold{h}(t) &= \phi(\bold{c}(t)) \odot \bold{o}(t)
\end{aligned}
$$

### Overall LSTM

$$
\begin{aligned}
    \bold{i}(t) &= \sigma \left( \bold{U}_i^T \bold{x}(t) + \bold{W}_i^T \bold{h}(t - 1) + \bold{b}_i \right) \\
    \bold{f}(t) &= \sigma \left( \bold{U}_f^T \bold{x}(t) + \bold{W}_f^T \bold{h}(t - 1) + \bold{b}_f \right) \\
    \bold{o}(t) &= \sigma \left( \bold{U}_o^T \bold{x}(t) + \bold{W}_o^T \bold{h}(t - 1) + \bold{b}_o \right) \\ \\

    \tilde{\bold{c}}(t) &= \phi \left( \bold{U}_c^T \bold{x}(t) + \bold{W}_c^T \bold{h}(t - 1) + \bold{b}_c \right) \\
    \bold{c}(t) &= \tilde{\bold{c}}(t) \odot \bold{i}(t) + \bold{c}(t - 1) \odot \bold{f}(t) \\
    \bold{h}(t) &= \phi(\bold{c}(t)) \odot \bold{o}(t)
\end{aligned}
$$

-   Most important component: State unit $c_i(t)$ (for time step $t$, cell $i$), which has a linear self-loop
-   Self-loop weight controlled by the forget gate unit, which sets this weight to a value between 0 and 1 via a sigmoid
-   This self-loop can produce paths where the gradient can flow for long durations, and make the weight on this self-loop conditioned on the context, rather than fixed

### Training LSTM Networks

![](train-lstm.png)

-   We have 3 matrices for each of the gates, for a total of 12 matrices
